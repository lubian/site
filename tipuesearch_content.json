{"pages":[{"url":"/pages/about-me.html","text":"Lu BIAN Current and Past: Current: Looking for a job in Data Science based in London Past: Data Scientist at Orange in Paris System and network Engineer at Orange in Paris Internship at Technicolor in Paris Master at Telecom Paristech and Eurecom in France Bachelor at Nanjing University in China Online presence GitHub repos: en LinkedIn profile: en","tags":"About Me","title":"About Me"},{"url":"/mistry.html","text":"Mistry","tags":"Paintings&Drawings","title":"Mistry"},{"url":"/stock-price-analysis-with-timeseries.html","text":"A little exercise with time series to explore the trend and the volatility of a stock as well as the linearity between the price change and the volume. To analyse the trend, a moving average over a window of 100 days is used To analyse the valiatility, a moving standard deviation over a window of 100 days is used. to analyse the relationship between the price change and the volume, the Standard Ordinary Least Square Regression is used. % matplotlib inline import matplotlib.pylab import numpy as np import pandas as pd import pandas.io.data as web get stock data frome yahoo via the pandas.io.data library data = web . get_data_yahoo ( \"GOOG\" , \"2000-01-01\" ) data . info () <class 'pandas.core.frame.DataFrame'> DatetimeIndex: 2907 entries, 2004-08-19 to 2016-03-07 Data columns (total 6 columns): Open 2907 non-null float64 High 2907 non-null float64 Low 2907 non-null float64 Close 2907 non-null float64 Volume 2907 non-null int64 Adj Close 2907 non-null float64 dtypes: float64(5), int64(1) memory usage: 159.0 KB data . head () Open High Low Close Volume Adj Close Date 2004-08-19 100.000168 104.060182 95.960165 100.340176 44871300 50.119968 2004-08-20 101.010175 109.080187 100.500174 108.310183 22942800 54.100990 2004-08-23 110.750191 113.480193 109.050183 109.400185 18342800 54.645447 2004-08-24 111.240189 111.600192 103.570177 104.870176 15319700 52.382705 2004-08-25 104.960181 108.000187 103.880180 106.000184 9232100 52.947145 # upsampling in case of missing date data_cpt = data . resample ( 'B' , fill_method = 'ffill' ) data_cpt [ 'Adj Close' ] . plot () # daily close price pd . rolling_mean ( data_cpt [ 'Adj Close' ], 100 ) . plot () # averaged daily price with moving window <matplotlib.axes._subplots.AxesSubplot at 0x10a841080> pd . rolling_std ( data_cpt [ 'Adj Close' ], 100 ) . plot () <matplotlib.axes._subplots.AxesSubplot at 0x10ac8f470> import matplotlib.pyplot as plt def stock ( symbol , criteria , starting_date ): data = web . get_data_yahoo ( symbol , starting_date ) data_cpt = data . resample ( 'B' , fill_method = 'ffill' ) plt . figure ( 1 ) plt . subplot ( 211 ) data_cpt [ criteria ] . plot () # daily close price pd . rolling_mean ( data_cpt [ criteria ], 100 ) . plot () # averaged daily price with moving window plt . subplot ( 212 ) pd . rolling_std ( data_cpt [ criteria ], 100 ) . plot () plt . show () stock ( 'SPY' , 'Adj Close' , '2000-01-01' ) Next we do the linear regression on moving window of a year And take the stock price of apple and S&P as example def reg_plot ( symb1 , symb2 , starting_date ): val1 = web . get_data_yahoo ( symb1 , starting_date )[ 'Adj Close' ] val2 = web . get_data_yahoo ( symb2 , starting_date )[ 'Adj Close' ] rets_1 = val1 . pct_change () rets_2 = val2 . pct_change () model = pd . ols ( y = rets_2 , x = { symb1 : rets_1 }, window = 250 ) return model reg_plot ( 'AAPL' , '&#94;NDX' , '2000-01-01' ) -------------------------Summary of Regression Analysis------------------------- Formula: Y ~ <AAPL> + <intercept> Number of Observations: 250 Number of Degrees of Freedom: 2 R-squared: 0.6148 Adj R-squared: 0.6132 Rmse: 0.0078 F-stat (1, 248): 395.7913, p-value: 0.0000 Degrees of Freedom: model 1, resid 248 -----------------------Summary of Estimated Coefficients------------------------ Variable Coef Std Err t-stat p-value CI 2.5% CI 97.5% -------------------------------------------------------------------------------- AAPL 0.5650 0.0284 19.89 0.0000 0.5093 0.6207 intercept 0.0004 0.0005 0.77 0.4420 -0.0006 0.0014 ---------------------------------End of Summary--------------------------------- reg_plot ( 'AAPL' , '&#94;NDX' , '2000-01-01' ) . beta [ 'AAPL' ] . plot () <matplotlib.axes._subplots.AxesSubplot at 0x10e22c2e8>","tags":"Data Mining","title":"stock price analysis with timeseries"},{"url":"/cat-in-watersoluble-pencil.html","text":"A cat could be unhappy, furious but also melancholy.","tags":"Paintings&Drawings","title":"cat in watersoluble pencil"},{"url":"/recursion-in-programing.html","text":"Recursion is widely used in computer science. Imagine to define a function f(n),let n denote the nth step, if we happen to known that f(n) is a function of f(n-1), f(n)=g(f(n-1)) , then we can use recursion to define the function f(n). The key of recursion is to use the same method g(x) recursively in future steps until the stop criteria is meeted. So three things must be defined: start point f(0) method recursively applied: g(x) * stop condition Here are some examples and implementations. calculate factorial: f(n) = n * f(n-1) calculate the factorial n!, which is the product of all numbers from 1 to n start : initiate from f(0)=1 each step : g(x)=n * x, repeatedly multiply k in step k stop : number of steps reaches n def step ( mul , k ): return mul * k def fac1 ( n ): if n == 0 : return 1 else : return step ( fac ( n - 1 ), n ) fac1 ( 4 ) 24 # or even make the step function anonymous def fac ( n ): if n == 0 : return 1 else : return n * fac ( n - 1 ) fac ( 4 ) # fac function is called n+1 times 24 calculate pi (approximation) pi = 4 * (1 - 1/3 + 1/5 - 1/7 + 1/9 -1/11 +1/13.... start : k=0 step : repeatedly add (-1)&#94;k/(2k+1) stop : difference between kth value and k-1th value is less than 0.00001 def pi ( n ): if n == 0 : return 4 else : return ( pi ( n - 1 ) + 4 * ( - 1 ) ** n / ( 2 * n + 1 )) pi ( 600 ) 3.143256545948974 calculate GCD (greatest common devisor) using Euclidean algorithm :g = gcd(a, b) = gcd(b, r0) = gcd(r0, r1) = … = gcd(rN−2, rN−1) = rN−1 start : two positive numbers a,b step : gcd(a,b) => gcd(b,a%b), repeatedly subtract the greater number buy a multiple of the smaller number, and call gcd using the smaller number and the remainder as input stop : gcd(r,0)=r def gcd ( a , b ): if ( b == 0 ): return a else : return gcd ( b , a % b ) gcd ( 6 , 16 ) 2 calculate sqare root by Newton's method: f(n) = f(n-1) + x/f(n-1) description of problem: given a positive number a, calculate the square root of a start : Start with an initial estimate y each step : g(x)=(x+a/x)/2, repeatedly improve the estimate by taking the mean of y and x/y, y(k)=mean(y(k),x/y(k)), so the error err(k) = abs((y(k)&#94;2-x)/x) stop : delta(k) < error # initial value y should not be 0 def closeEnough ( y , a ): return abs (( y * y - a ) / a ) < 0.01 def step ( y , a ): return ( y + a / y ) / 2 def sqrt_rec ( y , a ): if closeEnough ( y , a ): return y else : return sqrt_rec ( step ( y , a ), a ) sqrt_rec ( 1 , 9 ) 3.00009155413138 generate fibonacci sequence f(n)=f(n-1)+[seq[–1]+seq[–2]] fibonacci sequence 0, 1, 1, 2, 3, 5, 8, 13, ..., such that each number is the sum of two previous numbers(except the first two numbers: 0, 1) start : start from a fibonacci sequence,with the number of items to add N each step : g(x)=x+(x[-1]+x[-2]), repeateded add a number(which is the sum of last two numbers) into the sequence, while descreasing N by 1 stop : N==0 def fibo_step ( l ): l . append ( l [ - 2 ] + l [ - 1 ]) return l def fibo_gen ( l , N ): if N == 0 : return l else : return fibo_gen ( fibo_step ( l ), N - 1 ) fibo_gen ([ 0 , 1 ], 8 ) [0, 1, 1, 2, 3, 5, 8, 13, 21, 34] the generation of fibonacci sequence can be devided into two recursive parts: generate the nth fibonacci number f(n)=f(n-1)+f(n-2) generate fibonacci sequence with fibonacci number generate the nth fibonacci number f(n)=f(n-1)+f(n-2) def fibo ( n ): if n == 1 : return 0 elif n == 2 : return 1 else : return fibo ( n - 1 ) + fibo ( n - 2 ) fibo ( 10 ) 34 generate fibonacci sequence with fibonacci number def fibo_seq ( n ): if n == 1 : return [ 0 ] elif n == 2 : return [ 0 , 1 ] else : return fibo_seq ( n - 1 ) + [ fibo ( n )] fibo_seq ( 10 ) [0, 1, 1, 2, 3, 5, 8, 13, 21, 34] calculate a path from a tree graph def findPath ( graph , start , end , pathSoFar ): pathSoFar = pathSoFar + [ start ] if start == end : return pathSoFar if start not in graph : return None for node in graph [ start ]: if node not in pathSoFar : newpath = findPath ( graph , node , end , pathSoFar ) return newpath return None graph = { 'A' :[ 'B' , 'C' ], 'B' :[ 'C' , 'D' ], 'C' :[ 'D' ], 'D' :[ 'C' ], 'E' :[ 'F' ], 'F' :[ 'C' ]} findPath ( graph , 'A' , 'C' ,[]) ['A', 'B', 'C']","tags":"Data Mining","title":"Recursion in programing"},{"url":"/nudes-in-charcoal.html","text":"I wish to turn into light, Light that turns into ball, ball that rolls down your skin. I believe that human body is a landscape, with montains and valleys. A man's body is like a cello, muffled and veiled. Force is beneath the flesh, and lifted by bones.","tags":"Paintings&Drawings","title":"nudes in charcoal"},{"url":"/manipulating-data-with-linux-commands.html","text":"Here are a few commands that I often use before using a R or Python to explore the raw datasets. when facing a big file, it's better to have a brief look at the data before loading the whole data into memory. head -4 count forestfires.csv X,Y,month,day,FFMC,DMC,DC,ISI,temp,RH,wind,rain,area 7,5,mar,fri,86.2,26.2,94.3,5.1,8.2,51,6.7,0,0 7,4,oct,tue,90.6,35.4,669.1,6.7,18,33,0.9,0,0 7,4,oct,sat,90.6,43.7,686.9,6.7,14.6,33,1.3,0,0 however, it is quite difficult to see which data belongs to which column. I can use 'column' command to create a table view by indicating the separate symbol as comma. head -4 count forestfires.csv | column -t -s $',' X Y month day FFMC DMC DC ISI temp RH wind rain area 7 5 mar fri 86.2 26.2 94.3 5.1 8.2 51 6.7 0 0 7 4 oct tue 90.6 35.4 669.1 6.7 18 33 0.9 0 0 7 4 oct sat 90.6 43.7 686.9 6.7 14.6 33 1.3 0 0 to have an idea of the size(total number of lines) in the input file(s), I can use 'wc' command : wc -l forestfires.csv linux_command_data_manipulation.ipynb 518 forestfires.csv 125 linux_command_data_manipulation.ipynb 643 total to deal with blank lines, I use 'seb' command sed '/&#94;[[:space:]]*$/d' filename > new_filename to deal with duplicated lines, I use 'sort' and 'seb' command sort filename | uniq > new_filename to begin exploration with a small subset of the original file, I can for example extract the first 1000 lines and put it in a new file. head -n 1000 forestfires.csv > temp.csv when lines are ordered, it is better to sample the file to get 1000 lines instead of taking the first 1000 lines. One way is to use 'shuf' command. shuf -n 1000 filename to further explore data, csvkit is a nice tool, for example: - csvlook: data periscope - csvcut: data scalpel - csvstat: statistics without code - csvgrep: find the data you need - csvsort: order matters - csvjoin: merging related data other commands often used are: diff, grep, split, cut","tags":"Data Mining","title":"Manipulating data with linux commands"},{"url":"/skeleton-in-ink.html","text":"A skeleton is much more honest than a humain being.","tags":"Paintings&Drawings","title":"skeleton in ink"},{"url":"/monty-hall-problem-generalized-with-tree-diagram.html","text":"The Monty Hall problem. This is a much discussed puzzle, based on an old American game show. You are told that a prize is equally likely to be found behind any one of three closed doors in front of you. You point to one of the doors. A friend opens for you one of the remaining two doors, after making sure that the prize is not behind it. At this point, you can stick to your initial choice, or switch to the other unopened door. You win the prize if it lies behind your final choice of a door. Then will you Switch to the other unopened door or Stick to your initial choice. This is a probability problem, the goal is to find the strategy with maximum likelihood of wining. By intuition we know that the probability of wining is 1/3 since there are 3 doors with only one prize behind the door, which is equally likely to be found behind any of the three doors. However, another event happens after choosing: a friend opens for you one of the remaining two doors, after making sure that the prize is not behind it. This event surely add some useful information, but how is it measured quantitatively? A simple but useful way is to draw a tree diagram which list all the possiblities and calculate the conditional probabilities for each. Let's use graphviz to draw a tree diagram. from graphviz import Digraph import graphviz as gv tree = Digraph ( comment = 'Monty hall problem' ) tree . node ( \"A\" , \"choose from 3 doors\" ) tree . node ( \"B1\" , \"1/3\" ) tree . node ( \"B2\" , \"2/3\" ) tree . node ( \"B1_0\" , \"p=1/3 * 1 = 1/3\" ) tree . node ( \"B1_1\" , \"p=1/3 * 0 = 0\" ) tree . node ( \"B2_0\" , \"p=2/3 * 0 =0\" ) tree . node ( \"B2_1\" , \"p=2/3 * 1 = 2/3\" ) tree . edge ( \"A\" , \"B1\" , label = \"door with prize\" ) tree . edge ( \"A\" , \"B2\" , label = \"door without prize\" ) tree . edge ( \"B1\" , \"B1_0\" , label = \"not switch\" ) tree . edge ( \"B1\" , \"B1_1\" , label = \"switch\" ) tree . edge ( \"B2\" , \"B2_0\" , label = \"not switch\" ) tree . edge ( \"B2\" , \"B2_1\" , label = \"switch\" ) tree . render ( 'monty_hall' , view = True ) From the above tree, we see clearly that the probability of wining if not switch is 1/3+0=1/3, and the probability of wining if switch is 0+2/3=2/3 So the best strategy is to switch! To generalize the problem, assume there are k doors with prize and m doors without prize, and we draw the tree diagram: g = Digraph ( comment = 'Monty hall problem generalized' ) g . node ( \"A\" , \"choose from k+m doors\" ) g . node ( \"B1\" , \"k/(k+m)\" ) g . node ( \"B2\" , \"m/(k+m)\" ) g . node ( \"B1_0\" , \"k/(k+m) * 1\" ) g . node ( \"B1_1\" , \"k/(k+m) * (k-1)/(k+m-2)\" ) g . node ( \"B2_0\" , \"m/(k+m) * 0=0\" ) g . node ( \"B2_1\" , \"m/(k+m) * k/(k+m-2)\" ) g . edge ( \"A\" , \"B1\" , label = \"door with prize\" ) g . edge ( \"A\" , \"B2\" , label = \"door without prize\" ) g . edge ( \"B1\" , \"B1_0\" , label = \"not switch: 1\" ) g . edge ( \"B1\" , \"B1_1\" , label = \"switch: (k-1)/(k+m-2)\" ) g . edge ( \"B2\" , \"B2_0\" , label = \"not switch: 0\" ) g . edge ( \"B2\" , \"B2_1\" , label = \"switch: k/(k+m-2)\" ) g . render ( 'monty_all_gen' , view = True ) From the new tree, we see that the probability of wining if not switch is k/(k+m) + 0 = k/(k+m), and the probability of wining if switch is k/(k+m) * (k-1)/(k+m-2) + m/(k+m) * k/(k+m-2) = k(k+m-1)/(k+m)(k+m-2) surely > k/(k+m) So in general the best strategy is to switch!","tags":"Statistics","title":"monty hall problem generalized with tree diagram"},{"url":"/random-sentences-generation-with-ngrams.html","text":"This script parses a document, such as a novel book, and generates random sentences by applying ngrams and conditional frequency distribution. Task 1: generate sentences by applying maximum likelihood and choose the most frequent word. Task 2: generate random sentences adding randomness based on the conditional frequency distribution. Task 2 is an improvement based on Task 1. The problem can be narrowed: given a word A, which is the most likely word B that follows A? And then we continue the same process to find C,the most likely word that follows B, etc. After serveral iterations, a random sentence is generated based on the maximum likelihood. The problem is then reduced to find a word Bmax that maximize the conditional probability P(Bi|A), Bi belongs to a set of words that follows A. as we know P(B|A)=P(A,B)/P(A) = counts of (A,B)/counts of (A) so to find the word B that maximize P(B|A) means to find the word B that maximize the counts of (A,B). Let's divide the task 1 into several parts for implementation: 1. parsing a book: this is done by the following function non_blankword 2. changing the list of words into ngrams(bigrams here) 3. count the conditional frequency distribution 4. find the word with maximum counts import random import nltk from nltk import ngrams import string import sys def remv ( mystr , punctuations ): '''(str)->str remove the listed punctuations in the string mystr ''' mystr = \"\" . join ([ c for c in mystr if c not in list ( punctuations )]) return mystr def non_blankword ( path ): '''(str)->list This function take string refering the path of a file and process the document in the file including strip blank lines, remove punctuations and split lines in lists. The output is a list of words ''' with open ( path ) as f : lines = [ line . strip () for line in f ] lines = [ remv ( line , string . punctuation ) for line in lines ] lines = [ l for l in lines if l ] lines = list ( l . split ( \" \" ) for l in lines ) lines = reduce ( lambda x , y : x + y , lines ) return lines #1. parsing a book: this is done by the function non_blankword path = \"AliceWonderland.txt\" listofwords = non_blankword ( path ) print ( listofwords [ 50 : 65 ]) ['I', 'Down', 'the', 'RabbitHole', 'Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her'] After parsing a whole book and get a list of words. The list a words is then reshaped into ngrams. Take bigrams as an example, the transformation is : ['happy','new','year','to','you']=>[('happy','new'),('new','year'),('year','to'),('to','you')] 2. #2. changing the list of words into ngrams(bigrams here) mygrams = list ( ngrams ( listofwords , n = 2 )) print ( mygrams [ 50 : 65 ]) [('I', 'Down'), ('Down', 'the'), ('the', 'RabbitHole'), ('RabbitHole', 'Alice'), ('Alice', 'was'), ('was', 'beginning'), ('beginning', 'to'), ('to', 'get'), ('get', 'very'), ('very', 'tired'), ('tired', 'of'), ('of', 'sitting'), ('sitting', 'by'), ('by', 'her'), ('her', 'sister')] #3. count the conditional frequency distribution cfd = nltk . ConditionalFreqDist () for i in mygrams : condition = i [ 0 ] cfd [ i [ 0 ]][ i [ 1 ]] += 1 # take the word 'Alice' as an example print dict ( cfd [ 'Alice' ]) {'replied': 9, 'all': 1, 'looked': 8, 'soon': 2, 'felt': 5, 'indignantly': 3, 'its': 2, 'whose': 1, 'how': 1, 'thinking': 1, 'with': 2, 'itll': 1, 'had': 11, 'to': 9, 'only': 1, 'glanced': 1, 'Now': 1, 'surprised': 1, 'gave': 1, 'flinging': 1, 'severely': 1, 'very': 6, 'Of': 2, 'every': 1, 'they': 1, 'not': 1, 'desperately': 1, 'sighed': 1, 'like': 1, 'did': 9, 'always': 1, 'joined': 1, 'theyre': 1, 'she': 5, 'found': 1, 'went': 5, 'CHAPTER': 1, 'because': 1, 'dodged': 1, 'Only': 1, 'shes': 1, 'dear': 1, 'living': 1, 'said': 11, 'opened': 1, 'for': 2, 'shall': 1, 'hastily': 4, 'looking': 1, 'seriously': 1, 'Nothing': 2, 'got': 1, 'whispered': 2, 'we': 1, 'after': 1, 'led': 1, 'crouched': 1, 'timidly': 2, 'quite': 4, 'What': 2, 'Stand': 1, 'besides': 1, 'put': 1, 'by': 1, 'Thats': 2, 'could': 11, 'loudly': 1, 'asked': 3, 'waited': 3, 'ventured': 4, 'quietly': 1, 'Exactly': 1, 'appeared': 1, 'folded': 1, 'angrily': 1, 'alone': 1, 'doubtfully': 1, 'thoughtfully': 1, 'or': 1, 'sadly': 1, 'would': 1, 'Did': 1, 'caught': 1, 'three': 1, 'But': 1, 'noticed': 2, 'recognised': 1, 'was': 17, 'more': 1, 'that': 2, 'started': 1, 'Well': 3, 'took': 1, 'but': 4, 'it': 1, 'sharply': 1, 'Whos': 1, 'herself': 1, 'he': 1, 'And': 3, 'Ive': 4, 'panted': 1, 'Come': 4, 'cautiously': 2, 'were': 1, 'feeling': 1, 'didnt': 1, 'called': 2, 'and': 16, 'remained': 1, 'turned': 1, 'gently': 1, 'an': 1, 'heard': 3, 'as': 11, 'guessed': 2, 'Call': 1, 'in': 9, 'watched': 1, 'You': 3, 'One': 1, 'Then': 2, 'Anything': 1, 'rather': 3, 'allow': 1, 'began': 7, 'Oh': 1, 'when': 2, 'who': 6, 'swallowing': 1, 'laughed': 1, 'Im': 3, 'you': 1, 'Why': 5, 'added': 1, 'Off': 1, 'tried': 1, 'again': 3, 'I': 8, 'knew': 1, 'jumping': 1, 'IM': 1, 'coming': 1, 'The': 2, 'wheres': 1, 'a': 6, 'kept': 1, 'Reeling': 1, 'considered': 1, 'It': 4, 'think': 1, 'thought': 12, 'without': 1, 'so': 1, 'Have': 1, 'remarked': 2, 'aloud': 1, 'the': 2, 'thats': 1} cfd [ 'Alice' ] . max () 'was' #4. find the word with maximum counts and generate a sentence def generate_model_max ( cfdist , word , steps = 10 ): ''' (dict,str,int) -> None this function print a 11 words which begins from the input word, and followed by a word chosen with maxmum counts from conditional frequency distribution in each step. no result is returned. ''' for i in range ( steps ): print ( word ) if cfdist [ word ]: word = cfdist [ word ] . max () else : print ( \"no other word after this word\" ) break generate_model_max ( cfd , 'Alice' ) Alice was a little thing said the Queen and the generate_model_max ( cfd , 'Alice' ) Alice was a little thing said the Queen and the generate_model_max ( cfd , 'the' ) the Queen and the Queen and the Queen and the This approach has some flaws: 1. sentence is determined by the start word, as you see above. 2. some words are tighted locked to each other, such as the word 'the' and 'Queen' One solution is to add some randomness in the selection of the following words while conserving their frequency distribution. Here is my implementation: 1. sort the list of all possible following words by their frequencies 2. count the cumulated frequencies 3. compare the randomly generated number with the list of cumulated freqencies and return the first word which is bigger than the number. def sort_by_value ( mydict ): ''' (dict) -> list this function takes mydict as input and return a list of all items sorted by value in decreasing order as output, it returns a list of 2-tupples. ''' return sorted ( mydict . items (), key = lambda x : x [ 1 ], reverse = True ) def counts_cumul ( l ): ''' (list) -> list this function takes a list 2-tupples as input, for each item i, it calculates the cumulated value of all the previous items and as output, it returns a list of 2-tupples. ''' if len ( l ) == 1 : return l else : list1 = [] for i in range ( len ( l )): if i == 0 : list1 . append (( l [ i ][ 0 ], l [ i ][ 1 ])) else : list1 . append (( l [ i ][ 0 ], l [ i ][ 1 ] + list1 [ i - 1 ][ 1 ])) return list1 def choose_random ( mydict ): ''' (dict) -> str this function takes mydict (which contains words as mydict.keys and counts of words as mydict.values) as input, and returns a randomly selected key taking account of the counts as proportions. ''' #change the un_ordered dictionary mydict to list #mylist = mydict.items() # or even generate a sorted list mylist = sort_by_value ( mydict ) # creat another list of 2-tupple while the second item is the cumulated value of counts list2 = counts_cumul ( mylist ) # generate a random number between the interval 1 and the sum of counts randnumber = random . randint ( 1 , list2 [ - 1 ][ 1 ]) # given a random number between the interval 1:sum of counts, find in list2 the first value greater than this # random number and return the relevant key for i in range ( len ( list2 )): if ( list2 [ i ][ 1 ] >= randnumber ): return list2 [ i ][ 0 ] def generate_model_rand ( cfdist , word , steps = 10 ): ''' (dict,str,int) -> None this function print a 10 words which begins from the input word, and followed by a word chosen randomly in accord with conditional frequency distribution in each step. no result is returned. ''' for i in range ( steps ): print ( word ) if cfdist [ word ]: word = choose_random ( cfdist [ word ]) else : print ( \"no other word after this word\" ) break Now we redo the same tests, by call twice the function with the same word \"Alice\", the sentence is generated randomly and the deadlock between 'the' and 'Queen' is broken. generate_model_rand ( cfd , 'Alice' ) Alice Well be so violently that were nine inches high generate_model_rand ( cfd , 'Alice' ) Alice in its eyes by the Cat a very uncomfortable generate_model_rand ( cfd , 'the' ) the Rabbit say that if he did you A CaucusRace The original script is available in random_sentence_ngrams.py which takes two parameters(name of document and the number indicating ngrams: if n=3, then it's trigrams) in the shell and do the phrase generation interactively with keyboard input information. Notice that document is an important element that influences the random sentences style. A modern english novel do differ a lot from a Shakespear play.","tags":"Data Mining","title":"random sentences generation with ngrams"},{"url":"/profile-in-silverpoint.html","text":"Every boy has a roman warrior fancy.","tags":"Paintings&Drawings","title":"profile in silverpoint"},{"url":"/flowers-in-watercolor.html","text":"I offer you a bunch of flowers that never fade. I love poppy flowers, for its stuning simplicity and beauty.","tags":"Paintings&Drawings","title":"flowers in watercolor"},{"url":"/landscape-in-watercolor.html","text":"There is a wonderland in the south of china, where montains are surrounded by water and mist. A purple world","tags":"Paintings&Drawings","title":"landscape in watercolor"},{"url":"/food-in-watercolor.html","text":"Water chestnut belongs to my childhood memories, associated with water, spine A jambon from parma Chinese Cabbage A mango from Madagascar fruits make life more tasty A balanced meal consists vegetables of different colors","tags":"Paintings&Drawings","title":"food in watercolor"},{"url":"/little-girl-in-charcoal-pencil.html","text":"This girl is the daughter of a friend. A quite instant of a lively girl.","tags":"Paintings&Drawings","title":"little girl in charcoal pencil"},{"url":"/cat-in-watercolor.html","text":"I drew my little cat Dodo in a poste card size. My little cat is always curious, she often strenches her neck to see what's happening up there. She can be quickly transformed into a builder with a little hat. She likes observing others, even when she lies down.","tags":"Paintings&Drawings","title":"cat in watercolor"},{"url":"/cats-in-charcoal-pencil.html","text":"cat could be human, well, at least, act like human","tags":"Paintings&Drawings","title":"cats in charcoal pencil"},{"url":"/flower-in-oil.html","text":"Blue flower, grow out of dark.","tags":"Paintings$Drawings","title":"flower in oil"},{"url":"/pensee-in-oil.html","text":"May I enter in your thoughts?","tags":"Paintings&Drawings","title":"pensee in oil"},{"url":"/blackcat-in-oil.html","text":"When she close her eyes, you can barely find her in the dark, but will she allow this ignorance?","tags":"Paintings&Drawings","title":"blackcat in oil"}]}